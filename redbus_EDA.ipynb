{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579c7ea5-6bed-441f-8a9d-6e347f440df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd9b8777-4694-4f13-a9c9-a234f2482164",
   "metadata": {},
   "source": [
    "# Steps\n",
    "\n",
    "## 1. [Libraries](#1.-Import-the-Libraries)\n",
    "## 2. [Analysis](#2.-Preliminary-Analysis)\n",
    "## [Preprocessing]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecc1e14-ecca-4ddd-a39c-53f1e6d6e347",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ðŸšŒ Bus Demand Forecasting Hackathon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349be54c-3f9c-4a6e-89a6-95974d010e29",
   "metadata": {},
   "source": [
    "### ðŸ“Œ Problem Statement\n",
    "\n",
    "Accurately forecasting demand for bus journeys is a complex task due to the influence of multiple factors. These include:\n",
    "\n",
    "- **Holiday calendars**\n",
    "- **Wedding seasons**\n",
    "- **Long weekends**\n",
    "- **School vacations**\n",
    "- **Exam schedules**\n",
    "- **Day-of-week effects**\n",
    "- **Regional holidays** (impact varies by region)\n",
    "\n",
    "> Not all holidays cause significant changes in demand, making this a non-trivial modeling problem.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ¯ Objective\n",
    "\n",
    "Develop a predictive model that forecasts the **total number of seats booked** for a given **route** and **date of journey**, exactly **15 days before the travel date**.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“‚ Provided Data\n",
    "\n",
    "You will be given historical data from the platform, which includes:\n",
    "\n",
    "- `seats_booked`: Number of seats booked (actual demand)\n",
    "- `date_of_journey`: The actual travel date\n",
    "- `date_of_issue`: The date when the ticket was booked\n",
    "- `search_data`: Number of user searches for a specific journey on a given booking date\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§  Challenge Details\n",
    "\n",
    "You need to predict the **final demand (total seats booked)** for each route, **15 days in advance** of the travel date.\n",
    "\n",
    "#### âœ… Example\n",
    "\n",
    "- **Route**: Source City \"A\" â†’ Destination City \"B\"\n",
    "- **Date of Journey (DOJ)**: `30-Jan-2025`\n",
    "- **Prediction Date**: `16-Jan-2025` (15 days prior to DOJ)\n",
    "\n",
    "Your model should predict the **total expected bookings** on the prediction date for the journey date.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“¥ Data Access\n",
    "\n",
    "Download the training and testing datasets from the links provided at the bottom of the problem statement.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”§ Next Steps\n",
    "\n",
    "1. Exploratory Data Analysis (EDA)\n",
    "2. Feature Engineering\n",
    "3. Model Building\n",
    "4. Evaluation and Validation\n",
    "5. Final Predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f5b6b6-77bb-4971-b928-0e73ff9e6f68",
   "metadata": {},
   "source": [
    "## 2. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10103c3f-c6ca-4b96-a22d-a03eff62561b",
   "metadata": {},
   "source": [
    "Data - https://www.analyticsvidhya.com/datahack/contest/redbus-data-decode-hackathon-2025/\n",
    "1. train_csv => rows - 67200, columns - 4\n",
    "  - ['doj', 'srcid', 'destid', 'final_seatcount']\n",
    "2. test_csv  => rows - 5900, columns - 4\n",
    "  - ['route_key', 'doj', 'srcid', 'destid']\n",
    "3. transactions.csv => rows - 22661000, columns - 11\n",
    "  - ['doj', 'doi', 'srcid', 'destid', 'srcid_region', 'destid_region',\n",
    "       'srcid_tier', 'destid_tier', 'cumsum_seatcount', 'cumsum_searchcount',\n",
    "       'dbd']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098eb9b1-0d91-43d3-a301-c110976325df",
   "metadata": {},
   "source": [
    "### 2.1. Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "462b4396-c9fc-4efb-97cb-a564c779f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bec1008-a933-413a-9faf-776fc9b825a5",
   "metadata": {},
   "source": [
    "#### Import Data from csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8418bd66-9728-458b-89d6-a6f727846f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "transactions_data = pd.read_csv(\"transactions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b20ab88e-cbea-4b71-889e-73fecff9c197",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_data.copy()\n",
    "test_df = test_data.copy()\n",
    "test_df = test_df.drop('route_key', axis = 1)\n",
    "trans_df = transactions_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b51320d7-efc0-48cb-ad25-13ffa5fa5bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape -> (67200, 4)\n",
      "transactions shape -> (2266100, 11)\n",
      "test shape -> (5900, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape ->\", train_df.shape)\n",
    "print(\"transactions shape ->\", trans_df.shape)\n",
    "print(\"test shape ->\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb984203-325f-45a7-933b-0c302e811fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [train_df, test_df, trans_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fd9032-5e1e-4056-9689-9c857e068bdd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### info() of dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7bd7fc0-b1ce-4885-bf6f-63d8e5439d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 67200 entries, 0 to 67199\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   doj              67200 non-null  object \n",
      " 1   srcid            67200 non-null  int64  \n",
      " 2   destid           67200 non-null  int64  \n",
      " 3   final_seatcount  67200 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 2.1+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5900 entries, 0 to 5899\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   doj     5900 non-null   object\n",
      " 1   srcid   5900 non-null   int64 \n",
      " 2   destid  5900 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 138.4+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2266100 entries, 0 to 2266099\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   doj                 object \n",
      " 1   doi                 object \n",
      " 2   srcid               int64  \n",
      " 3   destid              int64  \n",
      " 4   srcid_region        object \n",
      " 5   destid_region       object \n",
      " 6   srcid_tier          object \n",
      " 7   destid_tier         object \n",
      " 8   cumsum_seatcount    float64\n",
      " 9   cumsum_searchcount  float64\n",
      " 10  dbd                 int64  \n",
      "dtypes: float64(2), int64(3), object(6)\n",
      "memory usage: 190.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for i in dfs:\n",
    "    print(i.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc790d5b-06ff-4865-a0b6-ab2d1a2867d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Check for Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae0d9339-af55-48ed-93e7-900481a8af6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doj                0\n",
      "srcid              0\n",
      "destid             0\n",
      "final_seatcount    0\n",
      "dtype: int64 \n",
      "\n",
      "doj       0\n",
      "srcid     0\n",
      "destid    0\n",
      "dtype: int64 \n",
      "\n",
      "doj                   0\n",
      "doi                   0\n",
      "srcid                 0\n",
      "destid                0\n",
      "srcid_region          0\n",
      "destid_region         0\n",
      "srcid_tier            0\n",
      "destid_tier           0\n",
      "cumsum_seatcount      0\n",
      "cumsum_searchcount    0\n",
      "dbd                   0\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in dfs:   \n",
    "    print(i.isna().sum(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38661a6-3c6b-4fb9-8ac7-b4b7c94d5014",
   "metadata": {},
   "source": [
    "###### Insight\n",
    "- There are no Nulll values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec01b37-7313-4bc5-8203-4aa1c6491cb2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb14ff78-b970-47d7-9d14-7fe99367e9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in dfs:\n",
    "    print(i.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68eab39-5d0e-4cc8-b0c3-5c12e508f30b",
   "metadata": {},
   "source": [
    "###### Insights \n",
    "- No Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea1bc52-b92a-489c-a2d7-734bf1fda217",
   "metadata": {},
   "source": [
    "#### Coverting objects into Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a591c62-a258-4146-9d78-1ee34d02e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_item_list = ['doj', 'doi']\n",
    "\n",
    "for df in dfs:\n",
    "    for col in date_item_list:\n",
    "        if col in df.columns and df[col].dtype != 'datetime64[ns]':\n",
    "            df[col] = pd.to_datetime(df[col], format = '%Y-%m-%d')\n",
    "\n",
    "            # Extracting new columns with date columns\n",
    "            df[col + '_year'] = df[col].dt.year\n",
    "            df[col + '_month'] = df[col].dt.month\n",
    "            df[col + '_day'] = df[col].dt.day\n",
    "            df[col + '_dayofweek'] = df[col].dt.dayofweek\n",
    "            df[col + '_isweekend'] = df[col].dt.dayofweek.isin([5,6]).astype(int)\n",
    "\n",
    "            # Deleting the datetime datatype columns\n",
    "            df.drop([col], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d249bfa-9d29-4ad8-ac8c-a0a0709441f1",
   "metadata": {},
   "source": [
    "##### Mapping ID's with respective locations and tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b412812-af42-4484-a395-18f250fc2fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dic = {}\n",
    "# dictionary adds [location ID] as key and its [Location name], [Location Tier]\n",
    "for i, j in transactions_data.iterrows():\n",
    "    dic.update({j.values[2] : [j.values[4], j.values[6]]})\n",
    "    dic.update({j.values[3] : [j.values[5], j.values[7]]})\n",
    "\n",
    "dict(sorted(dic.items()))\n",
    "'''\n",
    "\n",
    "######################################################\n",
    "\n",
    "loc_dict = {1: ['Maharashtra and Goa', 'Tier2'],\n",
    " 2: ['Maharashtra and Goa', 'Tier 1'],\n",
    " 3: ['Andhra Pradesh', 'Tier2'],\n",
    " 4: ['East 1', 'Tier 4'],\n",
    " 5: ['Andhra Pradesh', 'Tier2'],\n",
    " 6: ['Andhra Pradesh', 'Tier 3'],\n",
    " 7: ['Rest of North', 'Tier2'],\n",
    " 8: ['Andhra Pradesh', 'Tier2'],\n",
    " 9: ['Tamil Nadu', 'Tier2'],\n",
    " 10: ['Andhra Pradesh', 'Tier 3'],\n",
    " 11: ['Rest of North', 'Tier 1'],\n",
    " 12: ['Rajasthan', 'Tier 1'],\n",
    " 13: ['East 1', 'Tier2'],\n",
    " 14: ['Maharashtra and Goa', 'Tier2'],\n",
    " 15: ['Tamil Nadu', 'Tier 3'],\n",
    " 16: ['Maharashtra and Goa', 'Tier 1'],\n",
    " 17: ['East 1', 'Tier2'],\n",
    " 18: ['Tamil Nadu', 'Tier 1'],\n",
    " 19: ['Madhya Pradesh', 'Tier 1'],\n",
    " 20: ['Tamil Nadu', 'Tier2'],\n",
    " 21: ['Maharashtra and Goa', 'Tier2'],\n",
    " 22: ['Rest of North', 'Tier2'],\n",
    " 23: ['East 1', 'Tier 1'],\n",
    " 24: ['Maharashtra and Goa', 'Tier2'],\n",
    " 25: ['East 1', 'Tier2'],\n",
    " 26: ['Tamil Nadu', 'Tier 4'],\n",
    " 27: ['Rest of North', 'Tier2'],\n",
    " 28: ['Andhra Pradesh', 'Tier 3'],\n",
    " 29: ['East 1', 'Tier2'],\n",
    " 30: ['Maharashtra and Goa', 'Tier 1'],\n",
    " 31: ['Maharashtra and Goa', 'Tier 4'],\n",
    " 32: ['Madhya Pradesh', 'Tier 1'],\n",
    " 33: ['Tamil Nadu', 'Tier 3'],\n",
    " 34: ['Kerala', 'Tier2'],\n",
    " 35: ['Tamil Nadu', 'Tier2'],\n",
    " 36: ['Delhi', 'Tier2'],\n",
    " 37: ['Rest of North', 'Tier 1'],\n",
    " 38: ['Rest of North', 'Tier 1'],\n",
    " 39: ['Tamil Nadu', 'Tier 3'],\n",
    " 40: ['Maharashtra and Goa', 'Tier 1'],\n",
    " 41: ['Rest of North', 'Tier 4'],\n",
    " 42: ['Karnataka', 'Tier2'],\n",
    " 43: ['Andhra Pradesh', 'Tier 1'],\n",
    " 44: ['Tamil Nadu', 'Tier2'],\n",
    " 45: ['Karnataka', 'Tier 1'],\n",
    " 46: ['Tamil Nadu', 'Tier 1'],\n",
    " 47: ['Andhra Pradesh', 'Tier 1'],\n",
    " 48: ['Tamil Nadu', 'Tier2']}\n",
    "\n",
    "################################## Train #############################################\n",
    "train_df[['srcid_region', 'srcid_tier']] = train_df['srcid'].apply(lambda x: pd.Series(loc_dict[x]))\n",
    "train_df[['destid_region', 'destid_tier']] = train_df['destid'].apply(lambda x: pd.Series(loc_dict[x]))\n",
    "\n",
    "################################## test #############################################\n",
    "test_df[['srcid_region', 'srcid_tier']] = test_df['srcid'].apply(lambda x: pd.Series(loc_dict[x]))\n",
    "test_df[['destid_region', 'destid_tier']] = test_df['destid'].apply(lambda x: pd.Series(loc_dict[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07f3f04-a1e2-432f-84d5-e32a020e2693",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e3131a6-a9d0-4dee-bef6-1d580e41a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [col for col in trans_df.columns if trans_df[col].dtype == 'O']\n",
    "# ['srcid_region', 'destid_region', 'srcid_tier', 'destid_tier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "77b6f8d7-3e35-4e20-adcf-3ce57bbe4330",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder(dtype = int)\n",
    "\n",
    "train_df[categorical_columns] = encoder.fit_transform(train_df[categorical_columns])\n",
    "test_df[categorical_columns] = encoder.fit_transform(test_df[categorical_columns])\n",
    "trans_df[categorical_columns] = encoder.fit_transform(trans_df[categorical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d98f93d-e637-4d35-8b69-125cd1cc2514",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "618a443d-c715-4bb8-b384-2ca13fed4a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(['final_seatcount'], axis = 1)\n",
    "y = train_df['final_seatcount']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "175666cf-94bd-41f1-81b8-a0397d3a7bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['srcid', 'destid', 'final_seatcount', 'doj_year', 'doj_month',\n",
      "       'doj_day', 'doj_dayofweek', 'doj_isweekend', 'srcid_region',\n",
      "       'srcid_tier', 'destid_region', 'destid_tier'],\n",
      "      dtype='object')\n",
      "Index(['srcid', 'destid', 'doj_year', 'doj_month', 'doj_day', 'doj_dayofweek',\n",
      "       'doj_isweekend', 'srcid_region', 'srcid_tier', 'destid_region',\n",
      "       'destid_tier'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns)\n",
    "print(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "87d4b1e4-c6cd-4ad0-a38d-05f4366ffcfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(504.88480654785326)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBRegressor()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred)) # 504.88480654785326\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7764668e-e7f4-48bb-8ebf-5c6c7209d079",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "24d2c567-e3a1-46dd-9453-549e4f3ddecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor()\n",
    "model.fit(X,y)\n",
    "y_pred = model.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "90e7a170-ca35-41dd-9419-7740a2acabd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(test_data['route_key'])\n",
    "final_df['final_seatcount'] = pd.Series(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5ab64690-a2ba-432b-b96d-d20698d0979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de90438-2e4f-4867-9995-51db9e963297",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
